{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "data=pd.read_csv(\"Data\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "data.head()\n",
    "\n",
    "# %%\n",
    "data.shape\n",
    "\n",
    "# %%\n",
    "data.isnull().sum()\n",
    "\n",
    "# %%\n",
    "data.shape\n",
    "data.info()\n",
    "\n",
    "# %%\n",
    "msno.matrix(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.drop(['customerID'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = pd.to_numeric(df.TotalCharges, errors='coerce') # missing\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[np.isnan(df['TotalCharges'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[df['tenure'] == 0].index\n",
    "df.drop(labels=df[df['tenure'] == 0].index, axis=0, inplace=True)\n",
    "df[df['tenure'] == 0].index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df[\"TotalCharges\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "df[numerical_cols].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "labels =[\"Churn: Yes\",\"Churn:No\"]\n",
    "values = [1869,5163]\n",
    "labels_gender = [\"F\",\"M\",\"F\",\"M\"]\n",
    "sizes_gender = [939,930 , 2544,2619]\n",
    "colors = ['#ff6666', '#66b3ff']\n",
    "colors_gender = ['#c2c2f0','#ffb3e6', '#c2c2f0','#ffb3e6']\n",
    "explode = (0.3,0.3)\n",
    "explode_gender = (0.1,0.1,0.1,0.1)\n",
    "textprops = {\"fontsize\":15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.pie(values, labels=labels,autopct='%1.1f%%',pctdistance=1.08, labeldistance=0.8,colors=colors, startangle=90,frame=True, explode=explode,radius=10, textprops =textprops, counterclock = True, )\n",
    "plt.pie(sizes_gender,labels=labels_gender,colors=colors_gender,startangle=90, explode=explode_gender,radius=7, textprops =textprops, counterclock = True, )\n",
    "#Draw circle\n",
    "centre_circle = plt.Circle((0,0),5,color='black', fc='white',linewidth=0)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.title('Churn Distribution w.r.t Gender: Male(M), Female(F)', fontsize=15, y=1.1)\n",
    "\n",
    "# show plot\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\",font_scale=1.1)\n",
    "ax = sns.kdeplot(df.MonthlyCharges[(df[\"Churn\"] == 'No') ],\n",
    "                color=\"Red\", shade = True);\n",
    "ax = sns.kdeplot(df.MonthlyCharges[(df[\"Churn\"] == 'Yes') ],\n",
    "                ax =ax, color=\"Blue\", shade= True);\n",
    "ax.legend([\"Not Churn\",\"Churn\"],loc='upper right');\n",
    "ax.set_ylabel('Density');\n",
    "ax.set_xlabel('Monthly Charges');\n",
    "ax.set_title('Distribution of monthly charges by churn');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churned = df[df[\"Churn\"] == 'Yes'][\"tenure\"]\n",
    "not_churned = df[df[\"Churn\"] == 'No'][\"tenure\"]\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(not_churned, bins=30, alpha=0.5, label='Not Churned', color='blue')\n",
    "plt.hist(churned, bins=30, alpha=0.5, label='Churned', color='red')\n",
    "plt.xlabel('Tenure (months)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Tenure by Churn Status')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Install keras-tuner\n",
    "%pip install keras-tuner\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "# Define the model with hyperparameters\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    hp_units1 = hp.Int('units1', min_value=10, max_value=50, step=10)\n",
    "    hp_units2 = hp.Int('units2', min_value=10, max_value=50, step=10)\n",
    "    model.add(layers.Dense(units=hp_units1, input_shape=(19,), activation='relu'))\n",
    "    model.add(layers.Dense(units=hp_units2, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='tuning_example'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Print the evaluation results for the best model\n",
    "def print_evaluated_results(model, X_train, y_train, X_test, y_test):\n",
    "    train_results = model.evaluate(X_train, y_train)\n",
    "    val_results = model.evaluate(X_test, y_test)\n",
    "    print(f\"Model performance for Training set\\n- Accuracy: {train_results[1]}\\n- Loss: {train_results[0]}\")\n",
    "    print(\"----------------------------------\")\n",
    "    print(f\"Model performance for Validation set\\n- Accuracy: {val_results[1]}\\n- Loss: {val_results[0]}\")\n",
    "\n",
    "print_evaluated_results(best_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.round(y_pred).astype(int)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.round(y_pred).astype(int)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
